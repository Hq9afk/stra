# Smart Task Resource Allocator (STRA)

A system based on a machine learning model (Decision Tree) to predict the required resource level (low / medium / high) for each AI task, helping to allocate resources efficiently in an operating system or cloud environment.

---

## ğŸ“ Project Structure

```
ai_task_allocator/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ iuput_data.csv           # Iutput data
â”‚   â”œâ”€â”€ ouput_data.csv           # Output data
â”‚   â””â”€â”€ train_data.csv           # Training data
â”œâ”€â”€ model/
â”‚   â”œâ”€â”€ train_model.py           # Model training
â”‚   â”œâ”€â”€ predictor.py             # Single and CSV prediction
â”‚   â””â”€â”€ model.pkl                # Saved model
â”œâ”€â”€ utils/
â”‚   â””â”€â”€ preprocessing.py         # Data processing functions
â”œâ”€â”€ test/
â”‚   â””â”€â”€ test_prediction.py       # Quick test
â”œâ”€â”€ generate_input_data.py       # Collect tasks metrics
â”œâ”€â”€ main.py                      # CLI program
â””â”€â”€ README.md                    # User guide
```

---

## âš™ï¸ Environment Requirements

- Python 3.8+
- Libraries:
  ```bash
  pip install -r requirements.txt
  ```

---

## ğŸš€ How to Run

### ğŸ”¹ Step 1: Collect task metrics

```bash
python generate_input_data.py
```
- Task metrics are collected and classified based on resource-consumption
- Collected data are used as input for AI model
- Saves data to `data/input_data.csv`
### ğŸ”¹ Step 2: Train the Model

```bash
python model/train_model.py
```

- Reads data from `data/train_data.csv`
- Saves the model to `model/model.pkl`

---

### ğŸ”¹ Step 3: Single Prediction (CLI)

```bash
python main.py
```

- Enter task information:
  ```
  Task type: data_analysis
  CPU usage (%): 50
  Memory usage (%): 40
  I/O usage (%): 30
  Duration (s): 60
  Priority: medium
  ```
- Result:
  ```
  ğŸ“Š Predicted resource allocation: MEDIUM
  ```

---

### ğŸ”¹ Step 4: Batch Prediction from CSV

```bash
python -c "from model import predictor; predictor.predict_from_csv('data/input_data.csv', 'data/output_data.csv')"
```

- Prints results to terminal
- Writes to `data/output.csv` 

---

### ğŸ”¹ Step 5: Quick Test

```bash
python test/test_prediction.py
```

- Runs a sample example to check the system
- Prints result to screen

---

## ğŸ§ª Sample Data (`train_data.csv`)

```csv
task_type,cpu_usage,mem_usage,io_usage,duration,priority,resource_allocated
System Idle Process,2094,0,0,0,unknown,medium
System,16,0,100,8126,low,medium
unknown,0,0,0,8127,low,medium
Registry,0,0,100,8128,low,medium
smss.exe,0,0,0,8126,low,medium
svchost.exe,0,0,0,8123,low,medium
...
```

---

## ğŸ“Œ Notes

- Tasks are automatically encoded using an internal mapping table.
- Can be extended to other models such as Random Forest, Logistic Regression.
- Suitable for OS environments, container schedulers, or cloud resource planners.

---

## ğŸ‘¥ Team Members

- **Member 1**: Preprocessing & workload monitoring system  
  - Built the workload simulation module
  - Collected system resource usage data using `psutil`
  - Created workload input for the AI model.

- **Member 2**: AI model training  
  - Designed and trained the prediction model using Random Forest
  - Handled data splitting, training, evaluation, and model saving.

- **Member 3**: Integration & testing  
  - Integrated the AI model with the system
  - Implemented `main.py` to process CSV input and write predictions. 
  - Performed functional testing.

- **Member 4**: Report & presentation  
  - Wrote project documentation, testing reports, and created presentation slides. 
  - Participated in overall testing.
